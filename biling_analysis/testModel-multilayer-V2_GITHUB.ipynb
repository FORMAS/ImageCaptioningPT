{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42x0bbTh_qsc"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9135,
     "status": "ok",
     "timestamp": 1664831000829,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "qEfKshQD_qsd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 11:15:04.202855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:15:04.202914: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os, json, math\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import efficientnet, EfficientNetV2M, EfficientNetV2L\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import regularizers\n",
    "import string\n",
    "\n",
    "\n",
    "seed = 111\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1664831002076,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "BipKr2a4_qse"
   },
   "outputs": [],
   "source": [
    "with open('../datasets/Flickr30k/dataset_flickr30k_all.json', 'r') as captionsJson:\n",
    "  captions = json.load(captionsJson)\n",
    "with open('../datasets/Flickr30k/dataset_flickr30k.json', 'r') as captionsJson:\n",
    "  info = json.load(captionsJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1664831028460,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "vPrBgwDT_qse"
   },
   "outputs": [],
   "source": [
    "# Path to the images\n",
    "IMAGES_PATH = \"../datasets/Flickr30k/flickr30k-images\"\n",
    "\n",
    "# Desired image dimensions\n",
    "IMAGE_SIZE = (384, 384)\n",
    "\n",
    "# Vocabulary size\n",
    "VOCAB_SIZE = 8249\n",
    "\n",
    "# Fixed length allowed for any sequence\n",
    "SEQ_LENGTH = 25\n",
    "\n",
    "# Other training parameters\n",
    "BATCH_SIZE = 25\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1enfCX9q_qsf"
   },
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22931,
     "status": "ok",
     "timestamp": 1664831054028,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "paYGaujC_qsg",
    "outputId": "7a0c4705-d02b-4d3b-d817-950c1a61118a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  29000\n",
      "Number of validation samples:  1014\n",
      "Number of test samples:  1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_captions_data(captionsfile):\n",
    "    \"\"\"Loads captions (text) data and maps them to corresponding images.\n",
    "\n",
    "    Args:\n",
    "        filename: Path to the text file containing caption data.\n",
    "\n",
    "    Returns:\n",
    "        caption_mapping: Dictionary mapping image names and the corresponding captions\n",
    "        text_data: List containing all the available captions\n",
    "    \"\"\"\n",
    "    caption_mapping = {}\n",
    "    text_data = []\n",
    "    images_to_skip = set()\n",
    "\n",
    "    for img_name, captions in captionsfile.items():\n",
    "        img_name = os.path.join(IMAGES_PATH, img_name)\n",
    "        for caption in captions:\n",
    "          tokens = caption.strip().split()\n",
    "\n",
    "          if img_name.endswith(\"jpg\") and img_name not in images_to_skip:\n",
    "              # We will add a start and an end token to each caption\n",
    "              # caption = \"<start> \" + caption.strip() + \" <end>\"\n",
    "              text_data.append(caption)\n",
    "\n",
    "              if img_name in caption_mapping:\n",
    "                  caption_mapping[img_name].append(caption)\n",
    "              else:\n",
    "                  caption_mapping[img_name] = [caption]\n",
    "\n",
    "    return caption_mapping, text_data\n",
    "\n",
    "\n",
    "def train_val_split(caption_data, train_n, val_n, test_n, shuffle=True):\n",
    "    \"\"\"Split the captioning dataset into train and validation sets.\n",
    "\n",
    "    Args:\n",
    "        caption_data (dict): Dictionary containing the mapped caption data\n",
    "        train_size (float): Fraction of all the full dataset to use as training data\n",
    "        shuffle (bool): Whether to shuffle the dataset before splitting\n",
    "\n",
    "    Returns:\n",
    "        Traning and validation datasets as two separated dicts\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Get the list of all image names\n",
    "    all_images = list(caption_data.keys())\n",
    "\n",
    "    # 2. Shuffle if necessary\n",
    "    if shuffle:\n",
    "        np.random.shuffle(all_images)\n",
    "\n",
    "    # 3. Split into training and validation sets\n",
    "    # train_size = int(len(caption_data) * train_size)\n",
    "    train_size=train_n\n",
    "    val_size=val_n\n",
    "    test_size=test_n\n",
    "\n",
    "    training_data = {\n",
    "        img_name: caption_data[img_name] for img_name in all_images[:train_size]\n",
    "    }\n",
    "    validation_data = {\n",
    "        img_name: caption_data[img_name] for img_name in all_images[train_size:train_size+val_size]\n",
    "    }\n",
    "    test_data = {\n",
    "        img_name: caption_data[img_name] for img_name in all_images[-test_size:]\n",
    "    }\n",
    "\n",
    "    # 4. Return the splits\n",
    "    return training_data, validation_data, test_data\n",
    "\n",
    "def train_val_split_karpathy(caption_data, info_data):\n",
    "    \"\"\"Split the captioning dataset into train and validation sets.\n",
    "\n",
    "    Args:\n",
    "        caption_data (dict): Dictionary containing the mapped caption data\n",
    "        train_size (float): Fraction of all the full dataset to use as training data\n",
    "        shuffle (bool): Whether to shuffle the dataset before splitting\n",
    "\n",
    "    Returns:\n",
    "        Traning and validation datasets as two separated dicts\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Get the list of all image names\n",
    "    all_images = list(caption_data.keys())\n",
    "    all_images = np.array(all_images)\n",
    "    train_idx, val_idx, test_idx = [], [], []\n",
    "\n",
    "    for image in info_data['images']:\n",
    "      if image['split'] == 'train':\n",
    "        train_idx.append(np.where(all_images==IMAGES_PATH + '/' + image['filename']))\n",
    "      if image['split'] == 'val':\n",
    "        val_idx.append(np.where(all_images==IMAGES_PATH + '/' + image['filename']))\n",
    "      if image['split'] == 'test':\n",
    "        test_idx.append(np.where(all_images==IMAGES_PATH + '/' + image['filename']))\n",
    "\n",
    "\n",
    "    training_data = {\n",
    "        img_name[0][0]: caption_data[img_name[0][0]] for img_name in all_images[train_idx]\n",
    "    }\n",
    "    validation_data = {\n",
    "        img_name[0][0]: caption_data[img_name[0][0]] for img_name in all_images[val_idx]\n",
    "    }\n",
    "    test_data = {\n",
    "        img_name[0][0]: caption_data[img_name[0][0]] for img_name in all_images[test_idx]\n",
    "    }\n",
    "\n",
    "    # 4. Return the splits\n",
    "    return training_data, validation_data, test_data\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "captions_mapping, text_data = load_captions_data(captions)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "# train_data, valid_data, test_data = train_val_split(captions_mapping, 29014, 1000, 1000)\n",
    "train_data, valid_data, test_data = train_val_split_karpathy(captions_mapping, info)\n",
    "print(\"Number of training samples: \", len(train_data))\n",
    "print(\"Number of validation samples: \", len(valid_data))\n",
    "print(\"Number of test samples: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_text = []\n",
    "for i in train_data.values(): train_data_text.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145000, 155070)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_text), len(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTSnr7Mp_qsh"
   },
   "source": [
    "## Vectorizing the text data\n",
    "\n",
    "We'll use the `TextVectorization` layer to vectorize the text data,\n",
    "that is to say, to turn the\n",
    "original strings into integer sequences where each integer represents the index of\n",
    "a word in a vocabulary. We will use a custom string standardization scheme\n",
    "(strip punctuation characters except `<` and `>`) and the default\n",
    "splitting scheme (split on whitespace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8056, 13313)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=None,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~0123456789')\n",
    "tokenizer.fit_on_texts(train_data_text)\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "VOCAB_SIZE=0\n",
    "out=0\n",
    "for word, q in ast.literal_eval(tokenizer.get_config()['word_counts']).items():\n",
    "  if q > 4: VOCAB_SIZE-=-1\n",
    "  else: out-=-1\n",
    "VOCAB_SIZE, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 14546,
     "status": "ok",
     "timestamp": 1664831072084,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "ejyqSkHy_qsh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 11:16:42.512423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-10-05 11:16:42.513861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:16:42.513901: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:16:42.513922: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:16:42.513942: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:16:42.513962: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:16:42.513982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:16:42.514002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:16:42.514023: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2025-10-05 11:16:42.514026: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-10-05 11:16:42.514997: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "\n",
    "strip_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "strip_chars = strip_chars.replace(\"<\", \"\")\n",
    "strip_chars = strip_chars.replace(\">\", \"\")\n",
    "\n",
    "vectorization = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQ_LENGTH,\n",
    "    standardize=custom_standardization,\n",
    "    pad_to_max_tokens=True\n",
    ")\n",
    "vectorization.adapt(train_data_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_and_resize(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMAGE_SIZE)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_input(img_path, captions):\n",
    "    return decode_and_resize(img_path), vectorization(captions)\n",
    "\n",
    "\n",
    "def make_dataset(images, captions):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
    "    dataset = dataset.shuffle(len(images), reshuffle_each_iteration=True)\n",
    "    dataset = dataset.map(process_input, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "test_dataset = make_dataset(list(test_data.keys()), list(test_data.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AHRcWrX_qsi"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1664831105515,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "lqjdE6MNWPyw"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1664831106833,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "AvENyMNu_qsi"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_cnn_model():\n",
    "    base_model = EfficientNetV2L(\n",
    "        input_shape=(*IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\",\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    base_model_out = base_model.output\n",
    "    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(base_model_out)\n",
    "    cnn_model = keras.models.Model(base_model.input, base_model_out)\n",
    "    return cnn_model\n",
    "\n",
    "\n",
    "class TransformerEncoderBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.dense_1 = layers.Dense(dense_dim, activation=\"relu\")\n",
    "        self.dense_2 = layers.Dense(embed_dim)\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training, mask=None):\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=None,\n",
    "            training=training,\n",
    "        )\n",
    "        \n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        out_2 = self.dense_1(out_1)\n",
    "        out_3 = self.dense_2(out_2) #512\n",
    "        out_3 = self.dropout(out_3, training=training)\n",
    "        \n",
    "        return self.layernorm_2(out_1 + out_3)\n",
    "\n",
    "class PositionalEmbedding_IMG(layers.Layer):\n",
    "    def __init__(self, sequence_length, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_encoding = positional_encoding(length=sequence_length, depth=embed_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, num_layers, rate=0.4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = layers.Dense(embed_dim, activation='relu')\n",
    "        self.pos_embedding = PositionalEmbedding_IMG(\n",
    "            embed_dim=embed_dim, sequence_length=r_size * c_size\n",
    "        )\n",
    "        self.enc_layers = [TransformerEncoderBlock(embed_dim, dense_dim, num_heads) \n",
    "                       for _ in range(num_layers)]\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "    def call(self, x, training, mask=None):\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len(H*W), d_model) 512\n",
    "        # length = tf.shape(x)[1]\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "          x = self.enc_layers[i](x, training, mask)\n",
    "        \n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.pos_encoding = positional_encoding(length=sequence_length, depth=embed_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.token_embeddings(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.embed_dim, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "class TransformerDecoderBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, ff_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
    "        )\n",
    "        self.ffn_layer_1 = layers.Dense(ff_dim, activation=\"relu\")\n",
    "        self.ffn_layer_2 = layers.Dense(embed_dim)\n",
    "\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "\n",
    "        self.dropout_1 = layers.Dropout(0.8)\n",
    "        self.dropout_2 = layers.Dropout(0.8)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, training, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, :, tf.newaxis], dtype=tf.int32)\n",
    "            combined_mask = tf.cast(mask[:, tf.newaxis, :], dtype=tf.int32)\n",
    "            combined_mask = tf.minimum(combined_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=combined_mask,\n",
    "            training=training,\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2, attention_scores = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "            training=training,\n",
    "            return_attention_scores=True\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        ffn_out = self.ffn_layer_1(out_2)\n",
    "        ffn_out = self.ffn_layer_2(ffn_out)\n",
    "        ffn_out = self.dropout_2(ffn_out, training=training)\n",
    "        ffn_out = self.layernorm_3(ffn_out + out_2, training=training)\n",
    "        \n",
    "        return ffn_out, attention_scores\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "class Decoder(layers.Layer):\n",
    "  def __init__(self, embed_dim, dense_dim, num_heads, n_layers, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.out = layers.Dense(VOCAB_SIZE, activation=\"softmax\")\n",
    "        self.embedding = PositionalEmbedding(\n",
    "            embed_dim=embed_dim, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE\n",
    "        )\n",
    "        self.decoder_layers = [TransformerDecoderBlock(embed_dim=embed_dim, ff_dim=FF_DIM, num_heads=heads)\n",
    "                                for _ in range(n_layers)]\n",
    "  def call(self, inputs, encoder_outputs, training, mask=None):\n",
    "        inputs = self.embedding(inputs)\n",
    "\n",
    "        # def call(self, inputs, encoder_outputs, training, mask=None)\n",
    "        for i in range(self.n_layers):\n",
    "            inputs, weights = self.decoder_layers[i](inputs, encoder_outputs, training, mask)\n",
    "        pred = self.out(inputs)\n",
    "        return pred\n",
    "  def pred(self, inputs, encoder_outputs, training, mask=None):\n",
    "        inputs = self.embedding(inputs)\n",
    "\n",
    "        # def call(self, inputs, encoder_outputs, training, mask=None)\n",
    "        layers_att_weights = []\n",
    "        for i in range(self.n_layers):\n",
    "            inputs, weights = self.decoder_layers[i](inputs, encoder_outputs, training, mask)\n",
    "            layers_att_weights.append(weights)\n",
    "        pred = self.out(inputs)\n",
    "        return pred, layers_att_weights\n",
    "\n",
    "class ImageCaptioningModel(keras.Model):\n",
    "    def __init__(\n",
    "        self, cnn_model, encoder, decoder, num_captions_per_image=5, image_aug=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.acc_tracker = keras.metrics.Mean(name=\"accuracy\")\n",
    "        self.num_captions_per_image = num_captions_per_image\n",
    "        self.image_aug = image_aug\n",
    "\n",
    "    def calculate_loss(self, y_true, y_pred, mask):\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "        mask = tf.cast(mask, dtype=loss.dtype)\n",
    "        loss *= mask\n",
    "        return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "    def calculate_accuracy(self, y_true, y_pred, mask):\n",
    "        accuracy = tf.equal(y_true, tf.argmax(y_pred, axis=2))\n",
    "        accuracy = tf.math.logical_and(mask, accuracy)\n",
    "        accuracy = tf.cast(accuracy, dtype=tf.float32)\n",
    "        mask = tf.cast(mask, dtype=tf.float32)\n",
    "        return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n",
    "\n",
    "    def _compute_caption_loss_and_acc(self, img_embed, batch_seq, training=True):\n",
    "        encoder_out = self.encoder(img_embed, training=training)\n",
    "        batch_seq_inp = batch_seq[:, :-1]\n",
    "        batch_seq_true = batch_seq[:, 1:]\n",
    "        mask = tf.math.not_equal(batch_seq_true, 0)\n",
    "        batch_seq_pred = self.decoder(\n",
    "            batch_seq_inp, encoder_out, training=training, mask=mask\n",
    "        )\n",
    "        loss = self.calculate_loss(batch_seq_true, batch_seq_pred, mask)\n",
    "        acc = self.calculate_accuracy(batch_seq_true, batch_seq_pred, mask)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        batch_img, batch_seq = batch_data\n",
    "        batch_loss = 0\n",
    "        batch_acc = 0\n",
    "\n",
    "        if self.image_aug:\n",
    "            batch_img = self.image_aug(batch_img)\n",
    "\n",
    "        img_embed = self.cnn_model(batch_img)\n",
    "        for i in range(self.num_captions_per_image):\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss, acc = self._compute_caption_loss_and_acc(\n",
    "                    img_embed, batch_seq[:, i, :], training=True\n",
    "                )\n",
    "\n",
    "                batch_loss += loss\n",
    "                batch_acc += acc\n",
    "\n",
    "            train_vars = (\n",
    "                self.encoder.trainable_variables + self.decoder.trainable_variables\n",
    "            )\n",
    "\n",
    "            grads = tape.gradient(loss, train_vars)\n",
    "\n",
    "            self.optimizer.apply_gradients(zip(grads, train_vars))\n",
    "\n",
    "        batch_acc /= float(self.num_captions_per_image)\n",
    "        self.loss_tracker.update_state(batch_loss)\n",
    "        self.acc_tracker.update_state(batch_acc)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n",
    "\n",
    "    def test_step(self, batch_data):\n",
    "        batch_img, batch_seq = batch_data\n",
    "        batch_loss = 0\n",
    "        batch_acc = 0\n",
    "\n",
    "        img_embed = self.cnn_model(batch_img)\n",
    "        for i in range(self.num_captions_per_image):\n",
    "            loss, acc = self._compute_caption_loss_and_acc(\n",
    "                img_embed, batch_seq[:, i, :], training=False\n",
    "            )\n",
    "\n",
    "            batch_loss += loss\n",
    "            batch_acc += acc\n",
    "\n",
    "        batch_acc /= float(self.num_captions_per_image)\n",
    "\n",
    "        self.loss_tracker.update_state(batch_loss)\n",
    "        self.acc_tracker.update_state(batch_acc)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.acc_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 7691,
     "status": "ok",
     "timestamp": 1664831137136,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "YCdgZU-Qn_8H"
   },
   "outputs": [],
   "source": [
    "EMBED_DIM = 512\n",
    "r_size, c_size=12, 12\n",
    "FF_DIM = 2048\n",
    "\n",
    "heads = 6\n",
    "cnn_model = get_cnn_model()\n",
    "encoder = Encoder(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=heads, num_layers=2)\n",
    "decoder = Decoder(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=heads, n_layers=2)\n",
    "caption_model = ImageCaptioningModel(\n",
    "    cnn_model=cnn_model, encoder=encoder, decoder=decoder, image_aug=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5ef07b02e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caption_model.load_weights('pesos/model.tf')\n",
    "caption_model.load_weights('pesos/colab/modelV2/drive-download-20230331T190528Z-001/model_V2.43-13.6821.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction=\"none\"\n",
    ")\n",
    "class LRSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, post_warmup_learning_rate, warmup_steps):\n",
    "        super().__init__()\n",
    "        self.post_warmup_learning_rate = post_warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        global_step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        warmup_progress = global_step / warmup_steps\n",
    "        warmup_learning_rate = self.post_warmup_learning_rate * warmup_progress\n",
    "        return tf.cond(\n",
    "            global_step < warmup_steps,\n",
    "            lambda: warmup_learning_rate,\n",
    "            lambda: self.post_warmup_learning_rate,)\n",
    "learning_rate = LRSchedule(post_warmup_learning_rate=5e-5, warmup_steps=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate,beta_1=0.9, beta_2=0.98,\n",
    "                                                      epsilon=1e-9), loss=cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 11:18:34.121922: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 117964800 exceeds 10% of free system memory.\n",
      "2025-10-05 11:18:34.220794: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 117964800 exceeds 10% of free system memory.\n",
      "2025-10-05 11:18:34.249090: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 117964800 exceeds 10% of free system memory.\n",
      "2025-10-05 11:18:34.296277: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 117964800 exceeds 10% of free system memory.\n",
      "2025-10-05 11:18:34.346600: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 117964800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 327s 8s/step - loss: 13.4732 - acc: 0.4031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13.473180770874023, 0.40774327516555786]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZx2qPOv_qsk"
   },
   "source": [
    "## Check sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_Z5fsrJa_dRP"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import matplotlib, einops\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "matplotlib.use('agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "f9tWNii-_qsk"
   },
   "outputs": [],
   "source": [
    "vocab = vectorization.get_vocabulary()\n",
    "index_lookup = dict(zip(range(len(vocab)), vocab))\n",
    "max_decoded_sentence_length = SEQ_LENGTH - 1\n",
    "test_images = list(test_data.keys())\n",
    "\n",
    "\n",
    "def generate_caption(sample_img):\n",
    "    attention_plot = defaultdict(list)\n",
    "    sample_img = decode_and_resize(sample_img)\n",
    "    img = sample_img.numpy().clip(0, 255).astype(np.uint8)\n",
    "\n",
    "    img = tf.expand_dims(sample_img, 0)\n",
    "    img = caption_model.cnn_model(img)\n",
    "\n",
    "    encoded_img = caption_model.encoder(img, training=False)\n",
    "\n",
    "    decoded_caption = \"<start> \"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_caption = vectorization([decoded_caption])[:, :-1]\n",
    "        mask = tf.math.not_equal(tokenized_caption, 0)\n",
    "        predictions, att_weights = caption_model.decoder.pred(\n",
    "            tokenized_caption, encoded_img, training=False, mask=mask\n",
    "        )\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = index_lookup[sampled_token_index]\n",
    "        \n",
    "        for j in range(heads):\n",
    "          attention_plot[j].append(tf.squeeze(att_weights[-1],0)[j][i])\n",
    "        if sampled_token == '[UNK]': continue\n",
    "        decoded_caption += \" \" + sampled_token\n",
    "        if sampled_token == \"<end>\":\n",
    "            break\n",
    "    decoded_caption = decoded_caption.replace(\"<start> \", \"\").strip()\n",
    "    return decoded_caption, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from scipy.stats import median_abs_deviation as mad\n",
    "from scipy.stats import iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_max(dict_tensor):\n",
    "    tensors = list(attention_plot.values())\n",
    "    return np.max(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f92041397b214cf187cc69d693887e92",
      "2ec26a8c4bfb4cda8e190bed3e002741",
      "9a0c683aba4040bd899714f72176c78c",
      "fb0ba7ffad764472867844a51fa94142",
      "61bb4d986e76498286aea4fdd2ec2db5",
      "7a6dd55dbddf40669b4f56898e1f7764",
      "d8d08c93110d4bcab162208e98106019",
      "cd8a0a2153b94a5c971195453fe19e79",
      "2fa5014f5a754657ac6d1574a8b4bf8f",
      "8b5872b8bf1749bbb04683d8cc75da15",
      "4f82c590ba894a71b3dde37bdefaae83"
     ]
    },
    "executionInfo": {
     "elapsed": 5485300,
     "status": "ok",
     "timestamp": 1664823080922,
     "user": {
      "displayName": "João Gondim",
      "userId": "06361215619043280502"
     },
     "user_tz": 180
    },
    "id": "ao6pDW2cAI5R",
    "outputId": "6fbcbc8e-a21c-484b-f376-7d55bbb11a78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1000/1000 [19:30<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "stds, mads, iqrs = defaultdict(list), defaultdict(list), defaultdict(list)\n",
    "d = defaultdict(list)\n",
    "\n",
    "sentences = {}\n",
    "save_figs = False\n",
    "j = 1\n",
    "layer=1\n",
    "for image in tqdm(test_images):\n",
    "  key = image.split('/')[4]\n",
    "  if key not in sentences.keys():\n",
    "      sentences[key] = {'references': [], 'candidate': None}\n",
    "  sentences[key]['references'] = [caption.replace(\"<start> \", \"\").replace(\" <end>\", \"\").strip()\n",
    "                                  for caption in test_data[image]]\n",
    "  if sentences[key]['candidate'] is None:\n",
    "      caption,attention_plot = generate_caption(image)\n",
    "      sentences[key]['candidate'] = [caption]\n",
    "      temp_image = np.array(Image.open(image))\n",
    "      len_result = len(caption.split(' '))\n",
    "      grid_size = max(int(np.ceil(len_result/2)), 2)\n",
    "      for head in range(0, 6):\n",
    "          if not os.path.isdir(f'flickr30k-attention-head{head}V2'):\n",
    "            os.mkdir(f'flickr30k-attention-head{head}V2')\n",
    "          if save_figs:\n",
    "              fig = plt.figure(figsize=(20, 20), dpi=150)\n",
    "              fig.tight_layout()\n",
    "          for i in range(len(caption.split(' '))):\n",
    "              temp_att = np.resize(attention_plot[head][i], (r_size, c_size))\n",
    "              d[caption.split(' ')[i]+f'_{head}'].append(temp_att)\n",
    "              std, mad_, iqr_ = np.std(temp_att.flatten()), mad(temp_att.flatten()), iqr(temp_att.flatten())\n",
    "              stds[caption.split(' ')[i]+f'_{head}'].append(std)\n",
    "              mads[caption.split(' ')[i]+f'_{head}'].append(mad_)\n",
    "              iqrs[caption.split(' ')[i]+f'_{head}'].append(iqr_)\n",
    "              if not save_figs: continue\n",
    "              cap_folder = f'flickr30k-attention-head{head}V2/'+caption.split(' ')[i]\n",
    "              if not os.path.isdir(f'flickr30k-attention-head{head}V2/'+caption.split(' ')[i]):\n",
    "                  os.mkdir(f'flickr30k-attention-head{head}V2/'+caption.split(' ')[i])\n",
    "              grid_size = min(1+int(np.ceil(len_result/2)), 5)\n",
    "              ax = fig.add_subplot(grid_size, grid_size, i+1)\n",
    "              plt.subplots_adjust(wspace=.7)\n",
    "              ax.set_title(caption.split(' ')[i], fontsize=16, pad=2)\n",
    "              ax.axis('off')\n",
    "              norm = Normalize(vmin=0, vmax=100)\n",
    "              img = ax.imshow(temp_image, aspect='auto')\n",
    "              ax.imshow(temp_att, cmap='Greens', alpha=0.8, extent=img.get_extent(), aspect='auto',)\n",
    "              cax = ax.inset_axes([1.05, .0, .08, 1])\n",
    "              cbar=fig.colorbar(ScalarMappable(norm=norm, cmap='Greens'), cax=cax, orientation=\"vertical\",\n",
    "                           format=\"{x:.2f}\")\n",
    "              cbar.ax.tick_params(labelsize=15)\n",
    "              cbar.set_ticks([0, 20, 40, 60, 80, 100])\n",
    "              cbar.set_ticklabels(['0%', '20%', '40%', '60%', '80%', '100%'])\n",
    "          if not save_figs: continue\n",
    "          plt.savefig(f'flickr30k-attention-head{head}V2/{key.replace(\".jpg\", \".pdf\")}',\n",
    "                      bbox_inches='tight')\n",
    "          plt.cla()\n",
    "          plt.close('all')\n",
    "          plt.clf()\n",
    "#           break\n",
    "#       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uma criança pequena joga na água <end>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/4188 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for k, v in tqdm(d.items()):\n",
    "    word, head = k.split('_')\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=100)\n",
    "    fig.tight_layout()\n",
    "    ax = fig.add_subplot()\n",
    "    ax.imshow(np.mean(np.array(d[k]), axis=0), cmap='Greens')\n",
    "    ax.axis('off')\n",
    "    cax = ax.inset_axes([1.05, .0, .08, 1])\n",
    "    norm = Normalize(vmin=0, vmax=100)\n",
    "    cbar=fig.colorbar(ScalarMappable(norm=norm, cmap='Greens'), cax=cax, orientation=\"vertical\",\n",
    "               format=\"{x:.2f}\")\n",
    "    cbar.ax.tick_params(labelsize=30)\n",
    "    cbar.set_ticks([0, 20, 40, 60, 80, 100])\n",
    "    cbar.set_ticklabels(['0%', '20%', '40%', '60%', '80%', '100%'])\n",
    "    plt.savefig(f\"flickr30k-attention-head{head}V2/{word}/{word}_mean.png\",\n",
    "                      bbox_inches='tight')\n",
    "    plt.cla()\n",
    "    plt.close('all')\n",
    "    plt.clf()\n",
    "    \n",
    "    f=None\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            # 👇️ alternatively use str()\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('flickr_attentionheads_stdsV2.json', 'w') as jsonFile:\n",
    "    json.dump(stds, jsonFile, indent=4, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('flickr_attentionheads_madsV2.json', 'w') as jsonFile:\n",
    "    json.dump(mads, jsonFile, indent=4, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('flickr_attentionheads_iqrsV2.json', 'w') as jsonFile:\n",
    "    json.dump(iqrs, jsonFile, indent=4, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('flickr_attentionheads_attentionmatrixV2.json', 'w') as jsonFile:\n",
    "    json.dump(d, jsonFile, indent=4, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "\n",
    "class COCOEvalCap:\n",
    "    def __init__(self,images,gts,res):\n",
    "        self.evalImgs = []\n",
    "        self.eval = {}\n",
    "        self.imgToEval = {}\n",
    "        self.params = {'image_id': images}\n",
    "        self.gts = gts\n",
    "        self.res = res\n",
    "\n",
    "    def evaluate(self):\n",
    "        imgIds = self.params['image_id']\n",
    "        gts = self.gts\n",
    "        res = self.res\n",
    "\n",
    "        # =================================================\n",
    "        # Set up scorers\n",
    "        # =================================================\n",
    "        print ('tokenization...')\n",
    "        tokenizer = PTBTokenizer()\n",
    "        gts  = tokenizer.tokenize(gts)\n",
    "        res = tokenizer.tokenize(res)\n",
    "\n",
    "        # =================================================\n",
    "        # Set up scorers\n",
    "        # =================================================\n",
    "        print ('setting up scorers...')\n",
    "        scorers = [\n",
    "            (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
    "            (Meteor(),\"METEOR\"),\n",
    "            (Rouge(), \"ROUGE_L\"),\n",
    "            (Cider(), \"CIDEr\")\n",
    "        ]\n",
    "\n",
    "        # =================================================\n",
    "        # Compute scores\n",
    "        # =================================================\n",
    "        eval = {}\n",
    "        for scorer, method in scorers:\n",
    "            print ('computing %s score...'%(scorer.method()))\n",
    "            score, scores = scorer.compute_score(gts, res)\n",
    "            if type(method) == list:\n",
    "                for sc, scs, m in zip(score, scores, method):\n",
    "                    self.setEval(sc, m)\n",
    "                    self.setImgToEvalImgs(scs, imgIds, m)\n",
    "                    print (\"%s: %0.3f\"%(m, sc))\n",
    "            else:\n",
    "                self.setEval(score, method)\n",
    "                self.setImgToEvalImgs(scores, imgIds, method)\n",
    "                print (\"%s: %0.3f\"%(method, score))\n",
    "        self.setEvalImgs()\n",
    "\n",
    "    def setEval(self, score, method):\n",
    "        self.eval[method] = score\n",
    "\n",
    "    def setImgToEvalImgs(self, scores, imgIds, method):\n",
    "        for imgId, score in zip(imgIds, scores):\n",
    "            if not imgId in self.imgToEval:\n",
    "                self.imgToEval[imgId] = {}\n",
    "                self.imgToEval[imgId][\"image_id\"] = imgId\n",
    "            self.imgToEval[imgId][method] = score\n",
    "\n",
    "    def setEvalImgs(self):\n",
    "        self.evalImgs = [eval for imgId, eval in self.imgToEval.items()]\n",
    "\n",
    "def calculate_metrics(rng,datasetGTS,datasetRES):\n",
    "    imgIds = rng\n",
    "    gts = {}\n",
    "    res = {}\n",
    "\n",
    "    imgToAnnsGTS = {ann['image_id']: [] for ann in datasetGTS['annotations']}\n",
    "    for ann in datasetGTS['annotations']:\n",
    "        imgToAnnsGTS[ann['image_id']] += [ann]\n",
    "\n",
    "    imgToAnnsRES = {ann['image_id']: [] for ann in datasetRES['annotations']}\n",
    "    for ann in datasetRES['annotations']:\n",
    "        imgToAnnsRES[ann['image_id']] += [ann]\n",
    "\n",
    "    for imgId in imgIds:\n",
    "        gts[imgId] = imgToAnnsGTS[imgId]\n",
    "        res[imgId] = imgToAnnsRES[imgId]\n",
    "\n",
    "    evalObj = COCOEvalCap(imgIds,gts,res)\n",
    "    evalObj.evaluate()\n",
    "    return evalObj.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = []\n",
    "\n",
    "sys = []\n",
    "\n",
    "for j, image in enumerate(sentences.keys()):\n",
    "    sys.append({'image_id':j, 'caption':sentences[image]['candidate'][0]})\n",
    "    refslist = []\n",
    "    for i, reference in enumerate(sentences[image]['references']):\n",
    "        final_ref = ''\n",
    "        r = reference.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        for word in r.split(' '):\n",
    "            if word in vocab and word != '':\n",
    "                final_ref += word + ' '\n",
    "        refs.append({'image_id':j, 'caption':final_ref})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetGTS,datasetRES = {'annotations':refs}, {'annotations':sys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 67218 tokens at 828522.63 tokens per second.\n",
      "PTBTokenizer tokenized 11607 tokens at 262566.44 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 10608, 'reflen': 10535, 'guess': [10608, 9608, 8608, 7609], 'correct': [6131, 2597, 1049, 417]}\n",
      "ratio: 1.0069292833411478\n",
      "Bleu_1: 0.578\n",
      "Bleu_2: 0.395\n",
      "Bleu_3: 0.267\n",
      "Bleu_4: 0.180\n",
      "computing METEOR score...\n",
      "METEOR: 0.182\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.398\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bleu_1': 0.5779600301658581,\n",
       " 'Bleu_2': 0.39524681608136714,\n",
       " 'Bleu_3': 0.2670156173739529,\n",
       " 'Bleu_4': 0.17972339557087477,\n",
       " 'METEOR': 0.18156448757285593,\n",
       " 'ROUGE_L': 0.398117854946767,\n",
       " 'CIDEr': 0.35982566779752767}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(range(1000),datasetGTS,datasetRES)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/image_captioning.ipynb",
     "timestamp": 1663259576283
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "108f5e6f86d342a895126471f8f0b75f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_891fe9e1fefb47de8a05655ab732c4bc",
      "placeholder": "​",
      "style": "IPY_MODEL_f60e1bd8f8aa4105be38e08602a9b121",
      "value": "  0%"
     }
    },
    "185c7cf8c6a4464e90821685d833c3ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b4bd0585fda41d0b53525a0108fe549": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7bbd349b1554818b67393d1010fabb9",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e789a06561e4577afcae34b403c487d",
      "value": 1000
     }
    },
    "2cb7fe3e4ec14d4db2f0372da7ef5ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62f024ad1def498480ead90cb14a2f36",
      "placeholder": "​",
      "style": "IPY_MODEL_e9c451a1075d4072a9d233601c275f50",
      "value": "100%"
     }
    },
    "2ec26a8c4bfb4cda8e190bed3e002741": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a6dd55dbddf40669b4f56898e1f7764",
      "placeholder": "​",
      "style": "IPY_MODEL_d8d08c93110d4bcab162208e98106019",
      "value": "100%"
     }
    },
    "2fa5014f5a754657ac6d1574a8b4bf8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "32d5bc66083e4d688c45362ff4d393d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cf964b3ec374db6a01fa1014ceb02e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407692ccf9d94981a41ee0f6f946dbd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "44f5e55db2134246ab0fcd660d1f51f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e789a06561e4577afcae34b403c487d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f060244025048feabf15e541af9d6e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76725cb3d0d34b96aa516d6df1c82040",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8e5045f505a4970932951a1c7b7287c",
      "value": 1000
     }
    },
    "4f82c590ba894a71b3dde37bdefaae83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53012c61915f4bc4abb6e9051e1ec50c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61a1ca7a732146dd9b3f7fb851c6697d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61bb4d986e76498286aea4fdd2ec2db5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "626f61d074ea4046b427cc5b904715e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "62f024ad1def498480ead90cb14a2f36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64ff3b1b32b64c5b9dbc0cb6d730ff42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "757fcf46af2c4235a989c4e32317d5bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76725cb3d0d34b96aa516d6df1c82040": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a6dd55dbddf40669b4f56898e1f7764": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dc26cb4f3e94ca48ea2ea38d68d52bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "891fe9e1fefb47de8a05655ab732c4bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89c987d8de85463f8dfc1cde0eebee85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b5872b8bf1749bbb04683d8cc75da15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e4cdfc2f55745efb4390c006992f6b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32d5bc66083e4d688c45362ff4d393d2",
      "placeholder": "​",
      "style": "IPY_MODEL_3cf964b3ec374db6a01fa1014ceb02e3",
      "value": " 1000/1000 [00:05&lt;00:00, 101.29it/s]"
     }
    },
    "98625bcb0206415b980782aa878934e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a0c683aba4040bd899714f72176c78c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd8a0a2153b94a5c971195453fe19e79",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fa5014f5a754657ac6d1574a8b4bf8f",
      "value": 1000
     }
    },
    "a785d97c31364f6d8ecc742a0e3bd16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_108f5e6f86d342a895126471f8f0b75f",
       "IPY_MODEL_d8dad098ada44260b0086577982d0cb0",
       "IPY_MODEL_f85db6a537d243af89b9f0aefd1e36fa"
      ],
      "layout": "IPY_MODEL_ac7ea5bf3a064bf6b08d95c8fff7d422"
     }
    },
    "aa28e20376ba40819ab723ebdd211b80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac7ea5bf3a064bf6b08d95c8fff7d422": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7783127fef04dd3bd3e7952de3d2b51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d64854907be747edaf138d8b16677459",
       "IPY_MODEL_dcfa1c7cff4d4f59a39a46da3b7ccecc",
       "IPY_MODEL_c578e849669a43a4ab45ea0e3529710a"
      ],
      "layout": "IPY_MODEL_757fcf46af2c4235a989c4e32317d5bd"
     }
    },
    "ba9aa4d2dacc4403a39d3d3e5e3f626c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c578e849669a43a4ab45ea0e3529710a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53012c61915f4bc4abb6e9051e1ec50c",
      "placeholder": "​",
      "style": "IPY_MODEL_7dc26cb4f3e94ca48ea2ea38d68d52bc",
      "value": " 1000/1000 [00:05&lt;00:00, 210.52it/s]"
     }
    },
    "c8e5045f505a4970932951a1c7b7287c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cce3c96091374bf98e4d9ca3dad264e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa28e20376ba40819ab723ebdd211b80",
      "placeholder": "​",
      "style": "IPY_MODEL_185c7cf8c6a4464e90821685d833c3ac",
      "value": " 1000/1000 [00:09&lt;00:00, 31.41it/s]"
     }
    },
    "cd8a0a2153b94a5c971195453fe19e79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d64854907be747edaf138d8b16677459": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98625bcb0206415b980782aa878934e8",
      "placeholder": "​",
      "style": "IPY_MODEL_fccc027ab4a64488a09d15f227b5ff01",
      "value": "100%"
     }
    },
    "d8d08c93110d4bcab162208e98106019": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8dad098ada44260b0086577982d0cb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba9aa4d2dacc4403a39d3d3e5e3f626c",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_626f61d074ea4046b427cc5b904715e7",
      "value": 0
     }
    },
    "d95b75495fa045f6bcfa7822055c1825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc28bd370571450f826288a26e0c6cbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e48123103c2c44daad97c4cefe399d22",
       "IPY_MODEL_2b4bd0585fda41d0b53525a0108fe549",
       "IPY_MODEL_cce3c96091374bf98e4d9ca3dad264e7"
      ],
      "layout": "IPY_MODEL_61a1ca7a732146dd9b3f7fb851c6697d"
     }
    },
    "dcfa1c7cff4d4f59a39a46da3b7ccecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89c987d8de85463f8dfc1cde0eebee85",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_407692ccf9d94981a41ee0f6f946dbd5",
      "value": 1000
     }
    },
    "e48123103c2c44daad97c4cefe399d22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d95b75495fa045f6bcfa7822055c1825",
      "placeholder": "​",
      "style": "IPY_MODEL_f273348ea326411a82e32edd5f91f061",
      "value": "100%"
     }
    },
    "e709cb15bdcb435792e925b4e0cb9aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2cb7fe3e4ec14d4db2f0372da7ef5ba4",
       "IPY_MODEL_4f060244025048feabf15e541af9d6e0",
       "IPY_MODEL_8e4cdfc2f55745efb4390c006992f6b0"
      ],
      "layout": "IPY_MODEL_fa1bccc578ee4baebb20c2ee942ba16f"
     }
    },
    "e9c451a1075d4072a9d233601c275f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f273348ea326411a82e32edd5f91f061": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f60e1bd8f8aa4105be38e08602a9b121": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7bbd349b1554818b67393d1010fabb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f85db6a537d243af89b9f0aefd1e36fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64ff3b1b32b64c5b9dbc0cb6d730ff42",
      "placeholder": "​",
      "style": "IPY_MODEL_44f5e55db2134246ab0fcd660d1f51f7",
      "value": " 0/1000 [00:00&lt;?, ?it/s]"
     }
    },
    "f92041397b214cf187cc69d693887e92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ec26a8c4bfb4cda8e190bed3e002741",
       "IPY_MODEL_9a0c683aba4040bd899714f72176c78c",
       "IPY_MODEL_fb0ba7ffad764472867844a51fa94142"
      ],
      "layout": "IPY_MODEL_61bb4d986e76498286aea4fdd2ec2db5"
     }
    },
    "fa1bccc578ee4baebb20c2ee942ba16f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb0ba7ffad764472867844a51fa94142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b5872b8bf1749bbb04683d8cc75da15",
      "placeholder": "​",
      "style": "IPY_MODEL_4f82c590ba894a71b3dde37bdefaae83",
      "value": " 1000/1000 [1:31:24&lt;00:00,  6.38s/it]"
     }
    },
    "fccc027ab4a64488a09d15f227b5ff01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
